{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64d716c-60a0-4f4e-8730-4edac7a95e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_openai in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.1.8)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langchain_openai) (0.2.4)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.26.0 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langchain_openai) (1.31.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.66 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (0.1.71)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (2.7.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.4.28)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain_openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain_openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2.2->langchain_openai) (3.10.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain_openai) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tqdm>4->openai<2.0.0,>=1.26.0->langchain_openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f25251db-d910-4ead-91a0-9e5ee9f3b2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.66)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langgraph) (0.2.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langchain-core<0.3,>=0.2->langgraph) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langchain-core<0.3,>=0.2->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.66 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langchain-core<0.3,>=0.2->langgraph) (0.1.71)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langchain-core<0.3,>=0.2->langgraph) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langchain-core<0.3,>=0.2->langgraph) (2.7.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langchain-core<0.3,>=0.2->langgraph) (8.2.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2->langgraph) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2->langgraph) (3.10.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2->langgraph) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2->langgraph) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2->langgraph) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2->langgraph) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vlad\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2->langgraph) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f5512b-6064-490d-9761-86ce83efba4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AZURE_API_KEY: d5c1ae66fe5a41fd82f61e0b9fe88470\n",
      "AZURE_API_VERSION: 2024-02-15-preview\n",
      "AZURE_DEPLOYMENT: gpt-4t\n",
      "AZURE_ENDPOINT: https://itp-azopenai-ne.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "%run \"environment_setup.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c140d6bf-2d31-4c48-9462-559d5edccef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tavily API Key: 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\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "dotenv_path = find_dotenv()\n",
    "if not dotenv_path:\n",
    "    raise FileNotFoundError(\"Could not find .env file\")\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Ensure TAVILY_API_KEY is loaded\n",
    "tavily_api_key = os.getenv('TAVILY_API_KEY')\n",
    "if not tavily_api_key:\n",
    "    raise ValueError(\"TAVILY_API_KEY is not set\")\n",
    "print(\"Tavily API Key:\", tavily_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "432483c4-9551-4a1b-8a60-0356be15ef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import END, MessageGraph\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=os.getenv('AZURE_API_VERSION'),\n",
    "    azure_deployment=os.getenv('AZURE_DEPLOYMENT'),\n",
    "    api_key=os.getenv('AZURE_API_KEY'),\n",
    "    azure_endpoint=os.getenv('AZURE_ENDPOINT'),\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "graph = MessageGraph()\n",
    "\n",
    "graph.add_node(\"oracle\", model)\n",
    "graph.add_edge(\"oracle\", END)\n",
    "\n",
    "graph.set_entry_point(\"oracle\")\n",
    "\n",
    "runnable = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f64d150-60c9-4860-9592-5ea417604a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 1 + 1?', id='24174228-0cc7-4214-be7c-7d42a1d0b448'),\n",
       " AIMessage(content='1 + 1 equals 2.', response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 15, 'total_tokens': 23}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_2f57f81c11', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-7171dd1f-6956-4dfc-b539-fb0882b83203-0', usage_metadata={'input_tokens': 15, 'output_tokens': 8, 'total_tokens': 23})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke(HumanMessage(\"What is 1 + 1?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c8ee8a-1133-4296-9683-e4c3b80d98f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "@tool\n",
    "def multiply(first_number: int, second_number: int):\n",
    "    \"\"\"Multiplies two numbers together.\"\"\"\n",
    "    return first_number * second_number\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=azure_api_version,\n",
    "    azure_deployment=azure_deployment,\n",
    "    api_key=azure_api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    temperature=0\n",
    ")\n",
    "model_with_tools = model.bind_tools([multiply])\n",
    "\n",
    "builder = MessageGraph()\n",
    "\n",
    "builder.add_node(\"oracle\", model_with_tools)\n",
    "\n",
    "tool_node = ToolNode([multiply])\n",
    "builder.add_node(\"multiply\", tool_node)\n",
    "\n",
    "builder.add_edge(\"multiply\", END)\n",
    "\n",
    "builder.set_entry_point(\"oracle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9803db3a-a28a-4fcd-ab8e-3fe3ffdf18a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "def router(state: List[BaseMessage]) -> Literal[\"multiply\", \"__end__\"]:\n",
    "    tool_calls = state[-1].additional_kwargs.get(\"tool_calls\", [])\n",
    "    if len(tool_calls):\n",
    "        return \"multiply\"\n",
    "    else:\n",
    "        return \"__end__\"\n",
    "\n",
    "# Assuming builder is an instance of MessageGraph or a similar class\n",
    "builder.add_conditional_edges(\"oracle\", router)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9f2bd85-9284-4b85-b5d0-4f01f7097f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 123 * 456?', id='7a1eaaf0-6895-4af5-be87-39f86e96522c'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Tf4JNzKRkfoc0wriMpuEOwIe', 'function': {'arguments': '{\"first_number\":123,\"second_number\":456}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 57, 'total_tokens': 76}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_2f57f81c11', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-36bdf673-134f-418d-b445-c8dc0e90c981-0', tool_calls=[{'name': 'multiply', 'args': {'first_number': 123, 'second_number': 456}, 'id': 'call_Tf4JNzKRkfoc0wriMpuEOwIe'}], usage_metadata={'input_tokens': 57, 'output_tokens': 19, 'total_tokens': 76}),\n",
       " ToolMessage(content='56088', name='multiply', id='333235ed-6b7d-4c82-8e2d-304f14c237e2', tool_call_id='call_Tf4JNzKRkfoc0wriMpuEOwIe')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable = builder.compile()\n",
    "\n",
    "runnable.invoke(HumanMessage(\"What is 123 * 456?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab846bbb-a02d-4f30-a8a5-d86f94e72a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is your name?', id='cfe1d143-dad6-461d-8f24-db345dd1894b'),\n",
       " AIMessage(content='I am an AI digital assistant created by OpenAI, and I don\\'t have a personal name. You can refer to me as \"Assistant.\" How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 54, 'total_tokens': 91}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_2f57f81c11', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-2a41bde5-f006-4c98-a39e-2b94f2d6c9a8-0', usage_metadata={'input_tokens': 54, 'output_tokens': 37, 'total_tokens': 91})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke(HumanMessage(\"What is your name?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3111cb3-0a32-496c-add9-1335dc7b53fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TAVILY_API_KEY'] = tavily_api_key\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Initialize without passing the key, relying on the environment variable\n",
    "tools = [TavilySearchResults(max_results=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ad609b6-c9ca-4d57-a128-e20f2d096890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9e542ae-8efb-4798-acd1-321a11e62351",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8872b07-ea96-40fb-8eb0-bf763c6ede0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "\n",
    "def add_messages(left: list, right: list):\n",
    "    \"\"\"Add-don't-overwrite.\"\"\"\n",
    "    return left + right\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The `add_messages` function within the annotation defines\n",
    "    # *how* updates should be merged into the state.\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2569c39-a3a3-4610-b425-d56ef946bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state: AgentState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return \"__end__\"\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: AgentState):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aa312c0-fb61-4086-9314-061fd12da83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"tools\", 'agent')\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10a6ea8c-029a-4d5e-82a8-87ceae498e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather in sf'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_WA6MkZYhU4cE8o2T9H96wPh5', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 87, 'total_tokens': 109}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_2f57f81c11', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-e0e698e9-ebdc-4a6e-92bd-07ed5a48a1da-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_WA6MkZYhU4cE8o2T9H96wPh5'}], usage_metadata={'input_tokens': 87, 'output_tokens': 22, 'total_tokens': 109}),\n",
       "  ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1718006180, \\'localtime\\': \\'2024-06-10 0:56\\'}, \\'current\\': {\\'last_updated_epoch\\': 1718005500, \\'last_updated\\': \\'2024-06-10 00:45\\', \\'temp_c\\': 12.8, \\'temp_f\\': 55.0, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Overcast\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/122.png\\', \\'code\\': 1009}, \\'wind_mph\\': 12.5, \\'wind_kph\\': 20.2, \\'wind_degree\\': 250, \\'wind_dir\\': \\'WSW\\', \\'pressure_mb\\': 1015.0, \\'pressure_in\\': 29.98, \\'precip_mm\\': 0.01, \\'precip_in\\': 0.0, \\'humidity\\': 93, \\'cloud\\': 100, \\'feelslike_c\\': 11.3, \\'feelslike_f\\': 52.3, \\'windchill_c\\': 10.4, \\'windchill_f\\': 50.8, \\'heatindex_c\\': 12.1, \\'heatindex_f\\': 53.8, \\'dewpoint_c\\': 10.1, \\'dewpoint_f\\': 50.2, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 1.0, \\'gust_mph\\': 14.0, \\'gust_kph\\': 22.6}}\"}]', name='tavily_search_results_json', tool_call_id='call_WA6MkZYhU4cE8o2T9H96wPh5'),\n",
       "  AIMessage(content='The current weather in San Francisco is overcast with a temperature of 12.8°C (55.0°F). The wind is coming from the WSW at 20.2 kph (12.5 mph), and the humidity is at 93%. There is a slight precipitation of 0.01 mm, and the atmospheric pressure is 1015.0 mb. Visibility is 16 km (9 miles), and the UV index is at 1.0. The feels-like temperature is 11.3°C (52.3°F) due to the wind chill.', response_metadata={'token_usage': {'completion_tokens': 120, 'prompt_tokens': 531, 'total_tokens': 651}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_2f57f81c11', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-9102c47a-691c-4e04-855f-9376229347a4-0', usage_metadata={'input_tokens': 531, 'output_tokens': 120, 'total_tokens': 651})]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]}\n",
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c350cbb-ab48-4377-b6dc-4260a9e53233",
   "metadata": {},
   "outputs": [],
   "source": [
    "### STREAMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47a0cf06-22e5-4970-823e-c0ef9e40ca46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_GMAOFqE2eOYgmVUNNAX0dMzZ', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 87, 'total_tokens': 109}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_2f57f81c11', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-84a860fb-4244-45c4-b276-e1d2aef6ff85-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_GMAOFqE2eOYgmVUNNAX0dMzZ'}], usage_metadata={'input_tokens': 87, 'output_tokens': 22, 'total_tokens': 109})]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'tools':\n",
      "---\n",
      "{'messages': [ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1718006180, \\'localtime\\': \\'2024-06-10 0:56\\'}, \\'current\\': {\\'last_updated_epoch\\': 1718005500, \\'last_updated\\': \\'2024-06-10 00:45\\', \\'temp_c\\': 12.8, \\'temp_f\\': 55.0, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Overcast\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/122.png\\', \\'code\\': 1009}, \\'wind_mph\\': 12.5, \\'wind_kph\\': 20.2, \\'wind_degree\\': 250, \\'wind_dir\\': \\'WSW\\', \\'pressure_mb\\': 1015.0, \\'pressure_in\\': 29.98, \\'precip_mm\\': 0.01, \\'precip_in\\': 0.0, \\'humidity\\': 93, \\'cloud\\': 100, \\'feelslike_c\\': 11.3, \\'feelslike_f\\': 52.3, \\'windchill_c\\': 10.4, \\'windchill_f\\': 50.8, \\'heatindex_c\\': 12.1, \\'heatindex_f\\': 53.8, \\'dewpoint_c\\': 10.1, \\'dewpoint_f\\': 50.2, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 1.0, \\'gust_mph\\': 14.0, \\'gust_kph\\': 22.6}}\"}]', name='tavily_search_results_json', tool_call_id='call_GMAOFqE2eOYgmVUNNAX0dMzZ')]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='The current weather in San Francisco is overcast with a temperature of 12.8°C (55.0°F). The wind is coming from the WSW at 20.2 kph (12.5 mph), and the humidity is at 93%. Visibility is 16 km (9 miles), and there is a slight precipitation of 0.01 mm. The atmospheric pressure is 1015.0 mb. It feels like 11.3°C (52.3°F) due to the wind chill.', response_metadata={'token_usage': {'completion_tokens': 107, 'prompt_tokens': 531, 'total_tokens': 638}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_2f57f81c11', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-dbd641dc-aba6-4cd3-ad0a-36b5dbe92552-0', usage_metadata={'input_tokens': 531, 'output_tokens': 107, 'total_tokens': 638})]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]}\n",
    "for output in app.stream(inputs, stream_mode=\"updates\"):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee5463df-7870-4319-adca-b15f48d7bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]}\n",
    "async for output in app.astream_log(inputs, include_types=[\"llm\"]):\n",
    "    # astream_log() yields the requested logs (here LLMs) in JSONPatch format\n",
    "    for op in output.ops:\n",
    "        if op[\"path\"] == \"/streamed_output/-\":\n",
    "            # this is the output from .stream()\n",
    "            ...\n",
    "        elif op[\"path\"].startswith(\"/logs/\") and op[\"path\"].endswith(\n",
    "            \"/streamed_output/-\"\n",
    "        ):\n",
    "            # because we chose to only include LLMs, these are LLM tokens\n",
    "            print(op[\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387335cf-c436-4788-95bb-045f5688976b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
